#문장(시계열수치)입력 이진분류 모델 레시피1

#문장을 입력해서 이진분류하는 모델에 대해서 알아보겠다.
#언어가 시계열적인 의미가 있으므로, 이 언어를 문자로 표현한 문장도 시계열적인 의미가 있다. 
#모델에 입력하기 위해서 문장을 시계열수치로 인코딩하는 방법과 여러가지 이진분류 모델을 구성해보고, 학습 결과를 살펴보겠다. 
#이 모델들은 문장 혹은 시계열수치로 양성/음성을 분류하거나 이벤트 발생 유무를 감지하는 문제를 풀 수 있다.

#데이터셋 준비
#IMDB에서 제공하는 영화 리뷰 데이터셋을 이용하겠다.
#이 데이터셋은 훈련셋 25,000개, 시험셋 25,000개의 샘플을 제공한다. 
#라벨은 1과 0으로 좋아요/싫어요로 지정되어 있다. 
#케라스에서 제공하는 imdb의 load_data() 함수을 이용하면 데이터셋을 쉽게 얻을 수 있다. 
#데이터셋은 이미 정수로 인코딩되어 있으며, 정수값은 단어의 빈도수를 나타낸다. 
#모든 단어를 고려할 수 없으므로 빈도수가 높은 단어를 위주로 데이터셋을 생성한다. 
#20,000번째로 많이 사용하는 단어까지만 데이터셋으로 만들고 싶다면, num_words 인자에 20000이라고 지정하면 된다.
from keras.datasets import imdb
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)

print(x_train)

#총 25000개의 샘플이 있으며, 각 샘플은 영화 리뷰 한 건을 의미하며, 단어의 인덱스로 구성되어 있다. 
#‘num_words=20000’으로 지정했기 때문에 빈도수가 20,000을 넘는 단어는 보이지가 않는다.
#훈련셋 25,000개를 다시 훈련셋 20,000개와 검증셋 5,000개로 분리한다.
x_val = x_train[20000:]
y_val = y_train[20000:]
x_train = x_train[:20000]
y_train = y_train[:20000]

#리뷰의 길이가 다르니 각 샘플의 길이가 다르다.
#적게는 수십 단어로 많게는 천 개 이상의 단어로 구성되어 있다. 
#모델의 입력으로 사용하려면 고정된 길이로 만들어야 하므로 케라스에서 제공되는 전처리 함수인 sequence의 pad_sequences() 함수를 사용한다. 
#이 함수는 두 가지 역할을 수행한다.
#    - 문장의 길이를 maxlen 인자로 맞춰준다. 예를 들어 200으로 지정했다면 200보다 짧은 문장은 0으로 채워서 200단어로 맞춰주고 200보다 긴 문장은 200단어까지만 잘라낸다.
#    - (num_samples, num_timesteps)으로 2차원의 numpy 배열로 만들어준다. maxlen을 200으로 지정하였다면, num_timesteps도 200이 된다.
from keras.preprocessing import sequence

x_train = sequence.pad_sequences(x_train, maxlen=200)
x_val = sequence.pad_sequences(x_val, maxlen=200)
x_test = sequence.pad_sequences(x_test, maxlen=200)

#레이어 준비
#   - Embedding          : 단어를 의미론적 기하공간에 매핑할 수 있도록 벡터화시킨다.
#   - Conv1D             : 필터를 이용하여 지역적인 특징을 추출한다.
#   - GlobalMaxPooling1D : 여러 개의 벡터 정보 중 가장 큰 벡터를 골라서 반환한다.
#   - MaxPooling1D       : 입력벡터에서 특정 구간마다 값을 골라 벡터를 구성한 후 반환한다.
