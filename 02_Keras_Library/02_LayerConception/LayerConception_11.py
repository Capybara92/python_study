#순환 신경망 레이어 이야기

#순환 신경망 모델은 순차적인 자료에서 규칙적인 패턴을 인식하거나 그 의미를 추론할 수 있다.
#순차적이라는 특성 때문에 간단한 레이어로도 다양한 형태의 모델을 구성할 수 있다.
#케라스에서 제공하는 순환 신경망 레이어는 SimpleRNN, GRU, LSTM이 있으나 주로 사용하는 LSTM에 대해서 알아보겠다.

#긴 시퀀스를 기억할 수 있는 LSTM (Long Short-Term Memory units) 레이어
LSTM(3, input_dim=1)

#기본 인자는 다음과 같다.
#    - 첫번째 인자 : 메모리 셀의 개수이다.
#    - input_dim  : 입력 속성 수 이다.

#이는 앞서 살펴본 Dense 레이어 형태와 비슷하다.
#첫번째 인자인 메모리 셀의 개수는 기억용량 정도와 출력형태를 결정짓는다.
#Dense 레이어에서의 출력 뉴런 수와 비슷하다고 보시면 된다.
#input_dim에는 Dense레이어와 같이 일반적으로 속성의 개수가 들어간다.

#LSTM의 한 가지 인자에 대해 더 알아보겠다.
LSTM(3, input_dim=1, input_length=4)
#    - input_length : 시퀀스 데이터의 입력 길이
#Dense 레이어와 비교한다면 히든 뉴런들이 밖으로 도출되어 있음을 볼 수 있다.
#그리고 input_lengthㅇ가 길다고 해서 각 입력마다 다른 가중치를 사용하는 것이 아니라,
#입력 길이 만큼 연결한 것이기 때문에 모두 동일한 가중치를 공유한다.

#출력 형태
#    - return_sequences : 시퀀스 출력 여부
#LSTM 레이어는 return_sequences 인자에 따라 마지막 시퀀스에서 한 번만 출력할 수 있고 각 시퀀스에서 출력을 할 수 있다.
#many to many 문제를 풀거나 LSTM 레이어를 여러개로 쌓아올릴 때는 return_sequence=True 옵션을 사용한다.

#상태유지(stateful) 모드
#    - stateful : 상태 유지 여부
#학습 샘플의 가장 마지막 상태가 다음 샘플 학습 시에 입력으로 전달 여부를 지정하는 것이다.

#순환 신경망 레이어 중 LSTM 레이어에 대해서 알아봤다.
#사용법은 Dense 레이어와 비슷하지만 시퀀스 출력 여부와 상태유지 모드 설정으로 다양한 형태의 신경망을 구성할 수 있다.
